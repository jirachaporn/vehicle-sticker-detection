# api_service/camera.py
import os
import cv2
import numpy as np
from dotenv import load_dotenv
from ultralytics import YOLO
from fastapi import UploadFile
from PIL import Image
import io

# ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏à‡∏≤‡∏Å .env
load_dotenv()

MODEL_PATH = os.getenv("CET_DETECTION_PATH")
CAMERAS = {}

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLO ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö /car-detect
model = None
if MODEL_PATH and os.path.exists(MODEL_PATH):
    print(f"Loading YOLO model from: {MODEL_PATH}")
    model = YOLO(MODEL_PATH)
    print("‚úÖ YOLO model loaded successfully!")
else:
    print("‚ö†Ô∏è Model path not found or invalid:", MODEL_PATH)


async def detect_vehicle(file: UploadFile):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏¢‡∏≤‡∏ô‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û UploadFile"""
    if not model:
        raise RuntimeError("YOLO model not loaded")

    print(f"üöó [detect_vehicle] ‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏à‡∏≤‡∏Å Flutter ‡πÅ‡∏•‡πâ‡∏ß: {file.filename}")

    # ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å UploadFile
    image_bytes = await file.read()
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢ YOLO
    results = model(image_cv, conf=0.5)

    detections = []
    for result in results:
        boxes = result.boxes
        for box in boxes:
            cls_id = int(box.cls[0])
            conf = float(box.conf[0])
            bbox = box.xyxy[0].tolist()
            cls_name = model.names.get(cls_id, "Unknown")

            detections.append({
                "class": cls_id,
                "class_name": cls_name,
                "confidence": conf,
                "bbox": bbox,
            })

    # log ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    if detections:
        print(f"‚úÖ ‡∏û‡∏ö {len(detections)} ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏: {[d['class_name'] for d in detections]}")
    else:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ")

    return {
        "success": True,
        "filename": file.filename,
        "detections": detections,
        "count": len(detections),
    }


def stream_camera(camera_id: int):
    """Generator ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö StreamingResponse ‡∏Ç‡∏≠‡∏á FastAPI"""
    if camera_id not in CAMERAS:
        cap = cv2.VideoCapture(camera_id)
        if not cap.isOpened():
            return None
        CAMERAS[camera_id] = cap
    else:
        cap = CAMERAS[camera_id]

    def gen():
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            ret, buffer = cv2.imencode('.jpg', frame)
            frame_bytes = buffer.tobytes()
            yield (
                b'--frame\r\n'
                b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n'
            )

    return gen()


def check_available_cameras():
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏î‡πâ"""
    available = []
    for i in range(5):  # ‡∏•‡∏≠‡∏á‡πÄ‡∏ä‡πá‡∏Ñ‡∏Å‡∏•‡πâ‡∏≠‡∏á 0-4
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            available.append({"camera_id": i})
            cap.release()
    return available if available else None
